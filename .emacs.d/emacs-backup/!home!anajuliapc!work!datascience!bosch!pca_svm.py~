# coding=utf-8

import tensorflow as tf
import csv
import os
import itertools
import random
import linecache
import argparse
import sys
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from collections import defaultdict

if __name__ == '__main__':

    files = ['data/train_date.csv',
             'data/train_categorical.csv',
             'data/train_numeric.csv']

    # Get labels:
    labels = []
    with open(files[2], 'r') as f:
        reader = csv.reader(f)
        for row in reader:
            labels.append(row[-1])

    dataset = files[2]

    print(dataset)
    pca = PCA(n_components=21)
    data_pca_aux = pd.read_csv(dataset)
    print(data_pca_aux.shape)
    # data_pca = data_pca_aux.fillna(0)
    # #X = data.values
    # #X = scale(X)
    # data_reduced = pca.fit_transform(data_pca)
    # print(data_reduced.shape)
    # print(data_reduced)

    # #X = data.values
    # #X = scale(data_pca)
    # pca.fit(data_pca)
    # pca.components_.shape

    # #pca.components_
    # pca.explained_variance_ratio_
    # print(pca.components_.shape)
    # pca.components_[0].shape

    # print("deu tudo certo")
